{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "# import os\n",
        "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "#     for filename in filenames:\n",
        "#         print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2023-05-04T04:26:21.639173Z",
          "iopub.execute_input": "2023-05-04T04:26:21.639756Z",
          "iopub.status.idle": "2023-05-04T04:26:21.672037Z",
          "shell.execute_reply.started": "2023-05-04T04:26:21.639704Z",
          "shell.execute_reply": "2023-05-04T04:26:21.671262Z"
        },
        "trusted": true,
        "id": "Gf6LBrJSOI1Y",
        "outputId": "57a3f4da-a951-4a2d-cd84-d146f10c40eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "/kaggle/input/summarization-using-pegasus/data.csv\n/kaggle/input/summarization-using-pegasus-jayant/Summarization_dataset.csv\n/kaggle/input/summarization-final-dataset/final_dataset.csv\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cheQVftwOlTf",
        "outputId": "98ca0e27-9883-433a-c064-d4127555c97d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tweet-preprocessor\n",
        "!pip install rouge-score"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-04T04:26:21.674514Z",
          "iopub.execute_input": "2023-05-04T04:26:21.675308Z",
          "iopub.status.idle": "2023-05-04T04:26:41.643356Z",
          "shell.execute_reply.started": "2023-05-04T04:26:21.675270Z",
          "shell.execute_reply": "2023-05-04T04:26:41.642050Z"
        },
        "trusted": true,
        "id": "N34E850gOI1b",
        "outputId": "69f20d68-54a1-4a20-ee50-e2d8662a2049"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Requirement already satisfied: tweet-preprocessor in /opt/conda/lib/python3.10/site-packages (0.6.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: rouge-score in /opt/conda/lib/python3.10/site-packages (0.1.2)\nRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge-score) (1.4.0)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from rouge-score) (3.2.4)\nRequirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge-score) (1.16.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from rouge-score) (1.23.5)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import io\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from transformers import PegasusForConditionalGeneration, PegasusTokenizer, pipeline, AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer, AdamW\n",
        "import torch\n",
        "from datasets import load_dataset, Dataset, load_metric, DatasetDict\n",
        "from transformers.optimization import Adafactor, AdafactorSchedule\n",
        "import nltk\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.model_selection import train_test_split\n",
        "# import evaluate\n",
        "import gc\n",
        "import re\n",
        "from torch import nn\n",
        "import preprocessor as p\n",
        "\n",
        "\n",
        "torch_device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-04T04:26:41.645170Z",
          "iopub.execute_input": "2023-05-04T04:26:41.645756Z",
          "iopub.status.idle": "2023-05-04T04:26:42.071340Z",
          "shell.execute_reply.started": "2023-05-04T04:26:41.645718Z",
          "shell.execute_reply": "2023-05-04T04:26:42.069674Z"
        },
        "trusted": true,
        "id": "XG0kloPHOI1c",
        "outputId": "9f58cccc-13d4-45be-dbfe-75e560176573"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package omw-1.4 to /usr/share/nltk_data...\n[nltk_data]   Package omw-1.4 is already up-to-date!\n[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LOAD THE DATASET"
      ],
      "metadata": {
        "id": "JLYEy0TZOI1d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv('/content/drive/MyDrive/NLP_project/data/final_dataset.csv')\n",
        "dataset"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-04T04:26:42.074178Z",
          "iopub.execute_input": "2023-05-04T04:26:42.074819Z",
          "iopub.status.idle": "2023-05-04T04:26:42.125703Z",
          "shell.execute_reply.started": "2023-05-04T04:26:42.074780Z",
          "shell.execute_reply": "2023-05-04T04:26:42.124355Z"
        },
        "trusted": true,
        "id": "PPPxG9lmOI1e",
        "outputId": "586c84f5-0e1c-452f-ca47-535aa9e29883"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 31,
          "output_type": "execute_result",
          "data": {
            "text/plain": "                                                 inputs  \\\n0     Artificial intelligence is transforming the he...   \n1     The future of transportation is electric. With...   \n2     Remote work is here to stay, and it's changing...   \n3     Blockchain technology is transforming the way ...   \n4     The global food system is facing unprecedented...   \n...                                                 ...   \n1346  \"It's important to make time for the people an...   \n1347  \"Just took my dog for a long walk and feeling ...   \n1348  \"Happiness is not a destination, but a journey...   \n1349  \"Excited to announce that I'll be starting a n...   \n1350  \"In a world that can be so chaotic and divisiv...   \n\n                                              summaries  \n0     AI is revolutionizing healthcare by improving ...  \n1     EVs are the future of transportation, and as w...  \n2     Remote work is changing the way we balance wor...  \n3     Blockchain is transforming business by enablin...  \n4     Building a sustainable and equitable food syst...  \n...                                                 ...  \n1346  The tweet is about prioritizing the things and...  \n1347  The tweet is about going for a walk with a pet...  \n1348  The tweet is about the importance of enjoying ...  \n1349  The tweet is about starting a new job and expr...  \n1350  The tweet is about the importance of spreading...  \n\n[1351 rows x 2 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>inputs</th>\n      <th>summaries</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Artificial intelligence is transforming the he...</td>\n      <td>AI is revolutionizing healthcare by improving ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The future of transportation is electric. With...</td>\n      <td>EVs are the future of transportation, and as w...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Remote work is here to stay, and it's changing...</td>\n      <td>Remote work is changing the way we balance wor...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Blockchain technology is transforming the way ...</td>\n      <td>Blockchain is transforming business by enablin...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>The global food system is facing unprecedented...</td>\n      <td>Building a sustainable and equitable food syst...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1346</th>\n      <td>\"It's important to make time for the people an...</td>\n      <td>The tweet is about prioritizing the things and...</td>\n    </tr>\n    <tr>\n      <th>1347</th>\n      <td>\"Just took my dog for a long walk and feeling ...</td>\n      <td>The tweet is about going for a walk with a pet...</td>\n    </tr>\n    <tr>\n      <th>1348</th>\n      <td>\"Happiness is not a destination, but a journey...</td>\n      <td>The tweet is about the importance of enjoying ...</td>\n    </tr>\n    <tr>\n      <th>1349</th>\n      <td>\"Excited to announce that I'll be starting a n...</td>\n      <td>The tweet is about starting a new job and expr...</td>\n    </tr>\n    <tr>\n      <th>1350</th>\n      <td>\"In a world that can be so chaotic and divisiv...</td>\n      <td>The tweet is about the importance of spreading...</td>\n    </tr>\n  </tbody>\n</table>\n<p>1351 rows × 2 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PREPROCESSING"
      ],
      "metadata": {
        "id": "JMek3gacOI1f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tweets usually contain hashtags, emojis, links etc. So, before applying our model, we have to clean the dataset. To remove these unwanted characters, I have used tweet-preprocessor library which is twitter specific preprocessing library."
      ],
      "metadata": {
        "id": "FRMv4J_IOI1f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(58,64):\n",
        "    print(dataset['inputs'][i])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-04T04:26:42.127299Z",
          "iopub.execute_input": "2023-05-04T04:26:42.128086Z",
          "iopub.status.idle": "2023-05-04T04:26:42.141840Z",
          "shell.execute_reply.started": "2023-05-04T04:26:42.128047Z",
          "shell.execute_reply": "2023-05-04T04:26:42.140712Z"
        },
        "trusted": true,
        "id": "FLyWda1KOI1g",
        "outputId": "803d8972-5a9e-4bac-f62a-fbdd977aa467"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Nothing beats a morning run to start the day off right! 🏃‍♂️☀️ #morningmotivation\nAttended a yoga class for the first time today and it was such a calming experience 🧘‍♀️💆‍♀️ #yogalife\nJust finished reading a book on mindfulness and it has changed my perspective on life 📚🙏 #mindfulness\nStarted a new workout routine and already feeling the burn 🔥💪 #workoutmotivation\nTook a dance class for the first time in years and it was so much fun! 💃🎉 #dancelife\nJust finished a challenging hike and the view at the top was worth it! 🌄🥾 #hikingadventures\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for i in range(len(dataset['inputs'])):\n",
        "    dataset['inputs'][i] = p.clean(dataset['inputs'][i])\n",
        "    dataset['summaries'][i] = p.clean(dataset['summaries'][i])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-04T04:26:42.143985Z",
          "iopub.execute_input": "2023-05-04T04:26:42.145076Z",
          "iopub.status.idle": "2023-05-04T04:26:43.057243Z",
          "shell.execute_reply.started": "2023-05-04T04:26:42.145036Z",
          "shell.execute_reply": "2023-05-04T04:26:43.056067Z"
        },
        "trusted": true,
        "id": "ZhHJJR6iOI1g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(58,64):\n",
        "    print(dataset['inputs'][i])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-04T04:26:43.058670Z",
          "iopub.execute_input": "2023-05-04T04:26:43.059260Z",
          "iopub.status.idle": "2023-05-04T04:26:43.075079Z",
          "shell.execute_reply.started": "2023-05-04T04:26:43.059226Z",
          "shell.execute_reply": "2023-05-04T04:26:43.074060Z"
        },
        "trusted": true,
        "id": "zICmirnsOI1h",
        "outputId": "fb798531-b5a6-49d2-9a9a-1f71108c95dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Nothing beats a morning run to start the day off right!\nAttended a yoga class for the first time today and it was such a calming experience\nJust finished reading a book on mindfulness and it has changed my perspective on life\nStarted a new workout routine and already feeling the burn\nTook a dance class for the first time in years and it was so much fun!\nJust finished a challenging hike and the view at the top was worth it!\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SOUNDEX"
      ],
      "metadata": {
        "id": "2wzW_H6ucmAg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have used soundex to handle lexical variations in tweets. Often, the words we use while writing a tweet/message vary from person to person.\n",
        "Following can be the lexical variations of the word \"tomorrow\":\n",
        "‘2marrow’,  ‘2morow’, ‘2morrow’,\n",
        "‘tmmrw’, , ‘tmorrow’ ‘tmrow’, ‘tmrrow’, ‘tmrrw’, ‘tmrw’, ‘tmrww’, ‘tmw’,\n",
        "Thus, we need to normalize the words.\n",
        "I tried soundex to normalize them."
      ],
      "metadata": {
        "id": "GF_Q_-D4fMHA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import unicodedata\n",
        "# def soundex(s):\n",
        "\n",
        "#     if not s:\n",
        "#         return \"\"\n",
        "\n",
        "#     s = unicodedata.normalize(\"NFKD\", s)\n",
        "#     s = s.upper()\n",
        "\n",
        "#     replacements = (\n",
        "#         (\"BFPV\", \"1\"),\n",
        "#         (\"CGJKQSXZ\", \"2\"),\n",
        "#         (\"DT\", \"3\"),\n",
        "#         (\"L\", \"4\"),\n",
        "#         (\"MN\", \"5\"),\n",
        "#         (\"R\", \"6\"),\n",
        "#     )\n",
        "#     result = [s[0]]\n",
        "#     count = 1\n",
        "\n",
        "#     # find would-be replacment for first character\n",
        "#     for lset, sub in replacements:\n",
        "#         if s[0] in lset:\n",
        "#             last = sub\n",
        "#             break\n",
        "#     else:\n",
        "#         last = None\n",
        "\n",
        "#     for letter in s[1:]:\n",
        "#         for lset, sub in replacements:\n",
        "#             if letter in lset:\n",
        "#                 if sub != last:\n",
        "#                     result.append(sub)\n",
        "#                     count += 1\n",
        "#                 last = sub\n",
        "#                 break\n",
        "#         else:\n",
        "#             if letter != \"H\" and letter != \"W\":\n",
        "#                 # leave last alone if middle letter is H or W\n",
        "#                 last = None\n",
        "#         if count == 4:\n",
        "#             break\n",
        "\n",
        "#     result += \"0\" * (4 - count)\n",
        "#     return \"\".join(result)"
      ],
      "metadata": {
        "id": "hiT2k7F5c4bX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for i in range(len(dataset['inputs'])):\n",
        "#     dataset['inputs'][i] = p.clean(dataset['inputs'][i])\n",
        "#     dataset['summaries'][i] = p.clean(dataset['summaries'][i])\n",
        "#     temp = dataset['inputs'][i]\n",
        "#     temp = temp.split(\" \")\n",
        "#     updated_input=\"\"\n",
        "#     for word in temp:\n",
        "#         updated_input+=' '+ soundex(word)\n",
        "#     dataset['inputs'][i] = updated_input\n",
        "#     temp = dataset['summaries'][i]\n",
        "#     updated_summaries = \"\"\n",
        "#     for word in temp:\n",
        "#         updated_summaries+=' '+ soundex(word)\n",
        "#     dataset['summaries'][i] = updated_summaries"
      ],
      "metadata": {
        "id": "_3Ya_DZvdRMu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Splitting into train:validation:test :: 80:10:10"
      ],
      "metadata": {
        "id": "G-HgyqAjOI1h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train,rem = train_test_split(dataset, train_size=0.8)\n",
        "valid,test = train_test_split(rem, test_size=0.5)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-04T04:26:43.079604Z",
          "iopub.execute_input": "2023-05-04T04:26:43.080474Z",
          "iopub.status.idle": "2023-05-04T04:26:43.099327Z",
          "shell.execute_reply.started": "2023-05-04T04:26:43.080430Z",
          "shell.execute_reply": "2023-05-04T04:26:43.095782Z"
        },
        "trusted": true,
        "id": "xtoBolhsOI1h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Converting the dataset into model specific datatype"
      ],
      "metadata": {
        "id": "c5TyKzjqOI1h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = Dataset.from_dict(train)\n",
        "test = Dataset.from_dict(test)\n",
        "valid = Dataset.from_dict(valid)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-04T04:26:43.101112Z",
          "iopub.execute_input": "2023-05-04T04:26:43.101512Z",
          "iopub.status.idle": "2023-05-04T04:26:43.124663Z",
          "shell.execute_reply.started": "2023-05-04T04:26:43.101474Z",
          "shell.execute_reply": "2023-05-04T04:26:43.122362Z"
        },
        "trusted": true,
        "id": "CUgUbipEOI1h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tweets = DatasetDict({'train':train, 'valid':valid, 'test':test})\n",
        "tweets"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-04T04:26:43.134170Z",
          "iopub.execute_input": "2023-05-04T04:26:43.138177Z",
          "iopub.status.idle": "2023-05-04T04:26:43.152693Z",
          "shell.execute_reply.started": "2023-05-04T04:26:43.138128Z",
          "shell.execute_reply": "2023-05-04T04:26:43.151629Z"
        },
        "trusted": true,
        "id": "qLEFNpvNOI1i",
        "outputId": "e47e37c6-4822-495e-af43-2ae5614ae95b"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 37,
          "output_type": "execute_result",
          "data": {
            "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['inputs', 'summaries'],\n        num_rows: 1080\n    })\n    valid: Dataset({\n        features: ['inputs', 'summaries'],\n        num_rows: 135\n    })\n    test: Dataset({\n        features: ['inputs', 'summaries'],\n        num_rows: 136\n    })\n})"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LOADING THE MODEL(pegasus-xsum), TOKENIZER(pegasus), METRIC(rogue)"
      ],
      "metadata": {
        "id": "ZuUpRivcOI1i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'google/pegasus-xsum'\n",
        "\n",
        "# INITIALIZING PEGASUS TOKENIZER\n",
        "tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
        "\n",
        "#INITIALIZING PEGASUS MODEL\n",
        "model = PegasusForConditionalGeneration.from_pretrained(model_name)\n",
        "\n",
        "# EVALUATION METRIC\n",
        "metric = load_metric(\"rouge\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-04T04:26:43.157351Z",
          "iopub.execute_input": "2023-05-04T04:26:43.157671Z",
          "iopub.status.idle": "2023-05-04T04:27:04.506557Z",
          "shell.execute_reply.started": "2023-05-04T04:26:43.157645Z",
          "shell.execute_reply": "2023-05-04T04:27:04.505256Z"
        },
        "trusted": true,
        "id": "oMYOcACmOI1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FREEZING THE EMBEDDINGS\n"
      ],
      "metadata": {
        "id": "plScqOeLOI1i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To save the computation time in the Transformer package,\n",
        "embeddings are pre-computed up to the length of 512 and\n",
        "stored as a variable that serves as a cache which should not change during training.\n",
        "\n",
        "The reason for not training the position embeddings is that the embeddings for later positions would be undertrained,\n",
        " but with cleverly analytically defined position embeddings,\n",
        " the network can learn the regularity behind the equations and generalize for longer sequences more easily."
      ],
      "metadata": {
        "id": "AGFHQ1lAOI1i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def freeze_params(model):\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "freeze_params(model.model.shared)\n",
        "for d in [model.model.encoder, model.model.decoder]:\n",
        "  freeze_params(d.embed_positions)\n",
        "  freeze_params(d.embed_tokens)\n",
        "\n",
        "# # Freeze the embeddings\n",
        "# model.model.encoder.requires_grad = False\n",
        "# model.model.decoder.requires_grad = False"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-04T04:27:04.508404Z",
          "iopub.execute_input": "2023-05-04T04:27:04.509117Z",
          "iopub.status.idle": "2023-05-04T04:27:04.521698Z",
          "shell.execute_reply.started": "2023-05-04T04:27:04.509082Z",
          "shell.execute_reply": "2023-05-04T04:27:04.520603Z"
        },
        "trusted": true,
        "id": "_XvoaLsnOI1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TOKENIZE THE INPUTS AND SUMMARIES"
      ],
      "metadata": {
        "id": "unM7UMgQOI1j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before we can feed those texts to our model, we need to preprocess them. This is done by a pegasus tokenizer which will (as the name indicates) tokenize the inputs (including converting the tokens to their corresponding IDs in the pretrained vocabulary) and put it in a format the model expects, as well as generate the other inputs that the model requires."
      ],
      "metadata": {
        "id": "Wo_jDi23OI1j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_input_length = tokenizer.max_model_input_sizes[model_name]\n",
        "# MAX_MODEL_INPUT_SIZE FOR PEGASUS IS 512\n",
        "max_summary_length = 64\n",
        "\n",
        "def tokenizer_function(curr_dataset):\n",
        "    # Tokenizer for inputs\n",
        "    inputs = tokenizer(curr_dataset[\"inputs\"], max_length=max_input_length, truncation=True)\n",
        "\n",
        "    # Tokenizer for summaries\n",
        "    summaries = tokenizer(curr_dataset[\"summaries\"], max_length=max_summary_length, truncation=True)\n",
        "\n",
        "    ## Merging the tokens of summaries and inputs\n",
        "    inputs[\"labels\"] = summaries[\"input_ids\"]\n",
        "    # print(inputs)\n",
        "    return inputs\n",
        "\n",
        "tokenized_tweets = tweets.map(tokenizer_function,batched=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-04T04:27:04.523763Z",
          "iopub.execute_input": "2023-05-04T04:27:04.524569Z",
          "iopub.status.idle": "2023-05-04T04:27:05.301766Z",
          "shell.execute_reply.started": "2023-05-04T04:27:04.524530Z",
          "shell.execute_reply": "2023-05-04T04:27:05.292825Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "52a8f412d73543799442e5e8c089a333",
            "83123c3361644b0b99dafb8eb1b6fec2",
            "6c8ebfbfb36f4a6f9346c34338346dc4"
          ]
        },
        "id": "s1DKuH-wOI1j",
        "outputId": "3998df88-ab1f-430d-826b-117ab9508444"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/2 [00:00<?, ?ba/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "52a8f412d73543799442e5e8c089a333"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/1 [00:00<?, ?ba/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "83123c3361644b0b99dafb8eb1b6fec2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/1 [00:00<?, ?ba/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6c8ebfbfb36f4a6f9346c34338346dc4"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## INITIALIZING ARGUMENTS\n"
      ],
      "metadata": {
        "id": "NkmtXUtmOI1j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ARGUMENTS\n",
        "* evaluation_strategy - The evaluation strategy to adopt during training. \"epoch\" means evaluation is done at the end of each epoch.\n",
        "* per_device_train/eval_batch_size - The batch size per GPU/TPU core/CPU for training/eval.\n",
        "* weight_decay - The weight decay to apply to all layers except all bias and LayerNorm weights in AdamW optimizer.\n",
        "* predict_with_generate — Whether to use generate to calculate generative metrics.\n",
        "* save_total_limit -  If a value is passed, will limit the total amount of checkpoints. Deletes the older checkpoints in output_dir.\n"
      ],
      "metadata": {
        "id": "vXPTzVDaOI1j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "args = Seq2SeqTrainingArguments(\n",
        "    evaluation_strategy = \"epoch\", # evaluation is done at the end of each epoch.\n",
        "    learning_rate=5e-5,\n",
        "    per_device_train_batch_size=1, # batch size per device during training\n",
        "    per_device_eval_batch_size=1,  # batch size for evaluation\n",
        "    weight_decay=0.005,            # strength of weight decay\n",
        "    warmup_steps=500,\n",
        "    save_total_limit=3,\n",
        "    num_train_epochs=4,\n",
        "    predict_with_generate=True,\n",
        "    output_dir = 'none',\n",
        ")\n",
        "\n",
        "\n",
        "# Data collators are objects that will form a batch by using a list of dataset elements as input.\n",
        "# These elements are of the same type as the elements of train_dataset or eval_dataset.\n",
        "\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
        "\n",
        "# Optimizer : Parameters of the optimizer are taken as recommended in the documentation.\n",
        "optimizer = Adafactor(model.parameters(), scale_parameter=True, relative_step=True, warmup_init=True)\n",
        "lr_scheduler = AdafactorSchedule(optimizer)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-04T04:27:05.303311Z",
          "iopub.execute_input": "2023-05-04T04:27:05.303752Z",
          "iopub.status.idle": "2023-05-04T04:27:05.350907Z",
          "shell.execute_reply.started": "2023-05-04T04:27:05.303695Z",
          "shell.execute_reply": "2023-05-04T04:27:05.349884Z"
        },
        "trusted": true,
        "id": "I3xXi6kzOI1k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I didn't apply weight decay to 'bias' & 'LayerNorm' layers following the standards. But the ROUGE score was less. Below is the code for the approach."
      ],
      "metadata": {
        "id": "HJuJA7rXOI1k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
        "# params_0 = [p for n,p in named_parameters if \"embeddings\" in n\n",
        "#                 and any(nd in n for nd in no_decay)]\n",
        "# params_1 = [p for n,p in named_parameters if \"embeddings\" in n\n",
        "#                 and not any(nd in n for nd in no_decay)]\n",
        "\n",
        "# embed_params = {\"params\": params_0, \"lr\": lr, \"weight_decay\": 0.0}\n",
        "# opt_parameters.append(embed_params)\n",
        "#embed_params = {\"params\": params_1, \"lr\": lr, \"weight_decay\": 0.01}\n",
        "#opt_parameters.append(embed_params)\n",
        "# optimizer = Adafactor(opt_parameters, scale_parameter=True, relative_step=True, warmup_init=True)\n",
        "# lr_scheduler = AdafactorSchedule(optimizer)\n"
      ],
      "metadata": {
        "id": "giDYjawhOI1k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FUNCTION TO COMPUTE ROGUE SCORE INSIDE THE TRAINING LOOP"
      ],
      "metadata": {
        "id": "sFexZYTnOI1k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def metric_fn(eval_predictions):\n",
        "    predictions, labels = eval_predictions\n",
        "    decoded_predictions = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "    for label in labels:\n",
        "        label[label < 0] = tokenizer.pad_token_id  # Replace masked label tokens\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "    # Rouge expects a newline after each sentence\n",
        "    decoded_predictions = [\n",
        "        \"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_predictions\n",
        "    ]\n",
        "    decoded_labels = [\n",
        "        \"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels\n",
        "    ]\n",
        "    result = metric.compute(\n",
        "        predictions=decoded_predictions, references=decoded_labels, use_stemmer=True\n",
        "    )\n",
        "    # Extract a few results\n",
        "    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n",
        "    print(result)\n",
        "    # Add mean generated length\n",
        "    prediction_lens = [\n",
        "        np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions\n",
        "    ]\n",
        "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-04T04:27:05.352380Z",
          "iopub.execute_input": "2023-05-04T04:27:05.352923Z",
          "iopub.status.idle": "2023-05-04T04:27:05.367386Z",
          "shell.execute_reply.started": "2023-05-04T04:27:05.352890Z",
          "shell.execute_reply": "2023-05-04T04:27:05.366047Z"
        },
        "trusted": true,
        "id": "aXhZOH2TOI1k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TRAINING THE MODEL WITH APPROPRIATE PARAMETERS"
      ],
      "metadata": {
        "id": "M5xRk3uFOI1l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Seq2SeqTrainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset=tokenized_tweets[\"train\"],\n",
        "    eval_dataset=tokenized_tweets[\"valid\"],\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    optimizers=(optimizer, lr_scheduler),\n",
        "    compute_metrics=metric_fn\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-04T04:27:05.368928Z",
          "iopub.execute_input": "2023-05-04T04:27:05.369618Z",
          "iopub.status.idle": "2023-05-04T05:12:14.955911Z",
          "shell.execute_reply.started": "2023-05-04T04:27:05.369580Z",
          "shell.execute_reply": "2023-05-04T05:12:14.954276Z"
        },
        "trusted": true,
        "id": "6kDhKGttOI1l",
        "outputId": "57396a4a-fee6-48f3-a78b-77e7920423f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='2160' max='2160' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2160/2160 45:07, Epoch 4/4]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Rouge1</th>\n      <th>Rouge2</th>\n      <th>Rougel</th>\n      <th>Rougelsum</th>\n      <th>Gen Len</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.563500</td>\n      <td>1.074569</td>\n      <td>64.337232</td>\n      <td>46.307959</td>\n      <td>58.528214</td>\n      <td>58.535784</td>\n      <td>26.540741</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.012000</td>\n      <td>1.091732</td>\n      <td>59.396322</td>\n      <td>41.513633</td>\n      <td>54.007965</td>\n      <td>54.045972</td>\n      <td>21.829630</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.692200</td>\n      <td>1.226390</td>\n      <td>62.350464</td>\n      <td>43.535124</td>\n      <td>56.860943</td>\n      <td>57.119873</td>\n      <td>24.992593</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.575200</td>\n      <td>1.413349</td>\n      <td>62.216377</td>\n      <td>43.183369</td>\n      <td>56.427634</td>\n      <td>56.550777</td>\n      <td>24.822222</td>\n    </tr>\n  </tbody>\n</table><p>"
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "{'rouge1': 64.33723201608903, 'rouge2': 46.307958960807774, 'rougeL': 58.52821400839234, 'rougeLsum': 58.53578430984419}\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "{'rouge1': 59.39632181652219, 'rouge2': 41.51363258999879, 'rougeL': 54.007964951651964, 'rougeLsum': 54.04597177319425}\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "{'rouge1': 62.35046437502794, 'rouge2': 43.53512357827084, 'rougeL': 56.86094266999548, 'rougeLsum': 57.11987330563038}\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "{'rouge1': 62.216377293792156, 'rouge2': 43.18336889816483, 'rougeL': 56.42763440459995, 'rougeLsum': 56.550776742116696}\n",
          "output_type": "stream"
        },
        {
          "execution_count": 43,
          "output_type": "execute_result",
          "data": {
            "text/plain": "TrainOutput(global_step=2160, training_loss=0.9348672548929851, metrics={'train_runtime': 2708.9485, 'train_samples_per_second': 1.595, 'train_steps_per_second': 0.797, 'total_flos': 509426120589312.0, 'train_loss': 0.9348672548929851, 'epoch': 4.0})"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GENERATING SUMMARIES OF TEST TWEETS"
      ],
      "metadata": {
        "id": "DwIIVkunOI1l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output = trainer.predict(tokenized_tweets[\"test\"])\n",
        "sz = len(tokenized_tweets['test'])\n",
        "generated_summaries = []\n",
        "for i in range(0, sz):\n",
        "  generated_summaries.append(tokenizer.decode(output[0][i], skip_special_tokens =  True))\n",
        "given_summaries = tokenized_tweets[\"test\"][\"summaries\"]\n",
        "input_tweets = tokenized_tweets[\"test\"][\"inputs\"]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-04T05:12:14.957646Z",
          "iopub.execute_input": "2023-05-04T05:12:14.960789Z",
          "iopub.status.idle": "2023-05-04T05:13:45.664603Z",
          "shell.execute_reply.started": "2023-05-04T05:12:14.960751Z",
          "shell.execute_reply": "2023-05-04T05:13:45.663477Z"
        },
        "trusted": true,
        "id": "QOL38f_dOI1l",
        "outputId": "7d4232bd-dc4d-4664-be17-a0ae7e303286"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": ""
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "{'rouge1': 61.87638352369107, 'rouge2': 43.52033446338909, 'rougeL': 56.54791548153695, 'rougeLsum': 56.614247582772805}\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## METRICS OF TEST DATA"
      ],
      "metadata": {
        "id": "63Jh1macOI1l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output.metrics"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-04T05:13:45.666046Z",
          "iopub.execute_input": "2023-05-04T05:13:45.666632Z",
          "iopub.status.idle": "2023-05-04T05:13:45.679903Z",
          "shell.execute_reply.started": "2023-05-04T05:13:45.666597Z",
          "shell.execute_reply": "2023-05-04T05:13:45.678891Z"
        },
        "trusted": true,
        "id": "r_R-3DKKOI1m",
        "outputId": "8585130b-a7b4-4db8-eb9c-9cfbc86a4920"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 45,
          "output_type": "execute_result",
          "data": {
            "text/plain": "{'test_loss': 1.3670787811279297,\n 'test_rouge1': 61.87638352369107,\n 'test_rouge2': 43.52033446338909,\n 'test_rougeL': 56.54791548153695,\n 'test_rougeLsum': 56.614247582772805,\n 'test_gen_len': 23.095588235294116,\n 'test_runtime': 89.6402,\n 'test_samples_per_second': 1.517,\n 'test_steps_per_second': 0.759}"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PRECISION, RECALL AND F1 SCORE"
      ],
      "metadata": {
        "id": "QzfwePTEOI1m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bert_score\n",
        "from bert_score import score\n",
        "P, R, F1 = score(generated_summaries, given_summaries, lang=\"en\", verbose=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-04T05:13:45.681355Z",
          "iopub.execute_input": "2023-05-04T05:13:45.683635Z",
          "iopub.status.idle": "2023-05-04T05:14:08.526133Z",
          "shell.execute_reply.started": "2023-05-04T05:13:45.683598Z",
          "shell.execute_reply": "2023-05-04T05:14:08.525079Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "34b30b7944e3433db1e8d3137e071460",
            "e13df47649a14afc86b7b4e74aab0ba8"
          ]
        },
        "id": "dNNmXXMEOI1m",
        "outputId": "1b717959-d397-4cf4-8e42-481bb6768380"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Requirement already satisfied: bert_score in /opt/conda/lib/python3.10/site-packages (0.3.13)\nRequirement already satisfied: torch>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from bert_score) (2.0.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from bert_score) (1.23.5)\nRequirement already satisfied: transformers>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from bert_score) (4.28.1)\nRequirement already satisfied: tqdm>=4.31.1 in /opt/conda/lib/python3.10/site-packages (from bert_score) (4.64.1)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from bert_score) (21.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from bert_score) (2.28.2)\nRequirement already satisfied: pandas>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from bert_score) (1.5.3)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from bert_score) (3.6.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->bert_score) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.1->bert_score) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.1->bert_score) (2023.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert_score) (3.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert_score) (3.11.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert_score) (1.11.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert_score) (4.5.0)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert_score) (3.1.2)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert_score) (0.13.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert_score) (6.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert_score) (0.13.4)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert_score) (2023.3.23)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert_score) (1.4.4)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert_score) (4.39.3)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert_score) (0.11.0)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert_score) (9.5.0)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert_score) (1.0.7)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->bert_score) (2022.12.7)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->bert_score) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->bert_score) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->bert_score) (1.26.15)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas>=1.0.1->bert_score) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.0.0->bert_score) (2.1.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.0.0->bert_score) (1.3.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias']\n- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "calculating scores...\ncomputing bert embedding.\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/5 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "34b30b7944e3433db1e8d3137e071460"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "computing greedy matching.\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/3 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e13df47649a14afc86b7b4e74aab0ba8"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "done in 1.53 seconds, 89.02 sentences/sec\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Recall score: {R.mean():.3f}\")\n",
        "print(f\"Precision: {P.mean():.3f}\")\n",
        "print(f\"F1 score: {F1.mean():.3f}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-04T05:14:08.528014Z",
          "iopub.execute_input": "2023-05-04T05:14:08.529200Z",
          "iopub.status.idle": "2023-05-04T05:14:08.543781Z",
          "shell.execute_reply.started": "2023-05-04T05:14:08.529155Z",
          "shell.execute_reply": "2023-05-04T05:14:08.542643Z"
        },
        "trusted": true,
        "id": "FFdIYAIVOI1m",
        "outputId": "24b18d59-af4a-4143-9628-55b329f6d32c"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Recall score: 0.937\nPrecision: 0.945\nF1 score: 0.941\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## HERE ARE 5 TWEETS, THEIR GIVEN SUMMARY AND SUMMARY GENERATED BY THE MODEL"
      ],
      "metadata": {
        "id": "vP0rnyA7OI1m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TWEETS"
      ],
      "metadata": {
        "id": "j90tM3j_OI1m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_tweets[0:5]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-04T05:14:08.545431Z",
          "iopub.execute_input": "2023-05-04T05:14:08.546668Z",
          "iopub.status.idle": "2023-05-04T05:14:08.568565Z",
          "shell.execute_reply.started": "2023-05-04T05:14:08.546627Z",
          "shell.execute_reply": "2023-05-04T05:14:08.567439Z"
        },
        "trusted": true,
        "id": "6rtizaU4OI1m",
        "outputId": "08f30bb5-95c3-461a-8bd5-8f0e786680a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 48,
          "output_type": "execute_result",
          "data": {
            "text/plain": "['India Against Corruption is a grassroots movement aimed at combating corruption in Indian society and promoting transparency and accountability in government.',\n 'Twitter is constantly evolving and changing, with new features and updates being rolled out regularly. Let us stay informed and adapt to these changes to make the most of this platform.',\n 'Apple has always been at the forefront of innovation, and with the recent launch of the iPhone , they have once again proven why they are the leading technology company in the world. The new device boasts improved cameras, a faster processor, and a longer battery life, making it a must-have for anyone looking for the latest and greatest smartphone.',\n \"Tesla's Model S Plaid is the fastest production car ever made, with mind-boggling acceleration, top speed, and performance that puts it ahead of the competition.\",\n \"Microsoft's cloud computing platform, Azure, is one of the fastest-growing cloud services in the world. It offers a wide range of services, including virtual machines, data storage, and machine learning.\"]"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GIVEN SUMMARIES"
      ],
      "metadata": {
        "id": "u62v5sb4OI1m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "given_summaries[0:5]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-04T05:14:08.569495Z",
          "iopub.execute_input": "2023-05-04T05:14:08.569841Z",
          "iopub.status.idle": "2023-05-04T05:14:08.585678Z",
          "shell.execute_reply.started": "2023-05-04T05:14:08.569792Z",
          "shell.execute_reply": "2023-05-04T05:14:08.584729Z"
        },
        "trusted": true,
        "id": "Ky6E9wtyOI1n",
        "outputId": "d1347518-893b-4750-d0a1-d58a6b00538e"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 49,
          "output_type": "execute_result",
          "data": {
            "text/plain": "['This tweet introduces the India Against Corruption movement, highlighting its goal of eradicating corruption in Indian society and promoting government transparency and accountability.',\n \"A recognition of Twitter's constantly evolving nature and a call to stay informed and adapt to changes.\",\n \"Apple's iPhone launch shows their commitment to innovation with improved cameras, faster processors and a longer battery life.\",\n \"Tesla's Model S Plaid is the fastest production car ever made, with unmatched acceleration, top speed, and performance.\",\n 'Azure is a rapidly-growing cloud computing platform offered by Microsoft, with a variety of services including machine learning and data storage.']"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GENERATED SUMMARIES"
      ],
      "metadata": {
        "id": "uib9aOaGOI1n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generated_summaries[0:5]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-04T05:14:08.587095Z",
          "iopub.execute_input": "2023-05-04T05:14:08.587765Z",
          "iopub.status.idle": "2023-05-04T05:14:08.603003Z",
          "shell.execute_reply.started": "2023-05-04T05:14:08.587729Z",
          "shell.execute_reply": "2023-05-04T05:14:08.602085Z"
        },
        "trusted": true,
        "id": "xRxleAjlOI1n",
        "outputId": "e717a75b-a2de-4172-c21e-ec922de53c7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 50,
          "output_type": "execute_result",
          "data": {
            "text/plain": "[\"This tweet notes the grassroots movement's aim to combat corruption in Indian society and promote transparency and accountability in government.\",\n 'A call to stay informed and adapt to the latest features and updates on Twitter.',\n \"Apple's iPhone offers improved cameras, faster processor, and longer battery life.\",\n \"Tesla's Model S Plaid is the fastest production car ever, with incredible acceleration, top speed, and performance.\",\n \"Microsoft's cloud computing platform, Azure, offers a wide range of services, including virtual machines, data storage, and machine learning.\"]"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MQu8k0OjOI1n"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}